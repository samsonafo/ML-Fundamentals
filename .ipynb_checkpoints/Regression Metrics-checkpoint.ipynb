{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We cannot calculate **the accuracy for a regression model.**\n",
    "\n",
    "The skill or performance of a regression model must be reported as an error in those predictions.\n",
    "\n",
    "This makes sense if you think about it. If you are predicting a numeric value like a height or a dollar amount, you don’t want to know if the model predicted the value exactly (this might be intractably difficult in practice); instead, we want to know how close the predictions were to the expected values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Mean Absolute Error(MAE)**\n",
    "\n",
    "MAE calculates the **absolute** difference between actual and predicted values.\n",
    "\n",
    "To better understand, let’s take an example you have input data and output data and use Linear Regression, which draws a best-fit line.\n",
    "\n",
    "Now you have to find the MAE of your model which is basically a mistake made by the model known as an error. Now find the difference between the actual value and predicted value that is an absolute error but we have to find the mean absolute of the complete dataset.\n",
    "\n",
    "so, sum all the errors and divide them by a total number of observations And this is MAE. And we aim to get a minimum MAE because this is a loss.\n",
    "\n",
    "\n",
    "![Mean Absolute Error](./img/mae.png)\n",
    "\n",
    "```\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print(\"MAE\",mean_absolute_error(y_test,y_pred))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) **Mean Squared Error(MSE)**\n",
    "\n",
    "MSE is a most used and very simple metric with a little bit of change in mean absolute error. Mean squared error states that finding the squared difference between actual and predicted value.\n",
    "\n",
    "So, above we are finding the absolute difference and here we are finding the squared difference.\n",
    "\n",
    "What actually the MSE represents? It represents the squared distance between actual and predicted values. we perform squared to avoid the cancellation of negative terms and it is the benefit of MSE.\n",
    "\n",
    "![Mean Squared Error](./img/mse.png)\n",
    "\n",
    "```\n",
    "from sklearn.metrics import mean_squared_error\n",
    "print(\"MSE\",mean_squared_error(y_test,y_pred))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) **Root Mean Squared Error(RMSE)**\n",
    "\n",
    "As RMSE is clear by the name itself, that it is a simple square root of mean squared error.\n",
    "\n",
    "![Root Mean Squared Error](./img/rmse.png)\n",
    "\n",
    "To implement RMSE, we use the NumPy square root function:\n",
    "\n",
    "```\n",
    "\"RMSE\" = np.sqrt(mean_squared_error(y_test,y_pred))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) **R Squared (R2)**\n",
    "\n",
    "R2 score is a metric that tells the performance of your model, not the loss in an absolute sense that how well did your model perform.\n",
    "\n",
    "In contrast, MAE and MSE depend on the context as we have seen whereas the R2 score is independent of context.\n",
    "\n",
    "So, with help of R squared we have a baseline model to compare a model which none of the other metrics provides. The same we have in classification problems which we call a threshold which is fixed at 0.5. So basically R2 squared calculates how much regression line is better than a mean line.\n",
    "\n",
    "Hence, R2 squared is also known as Coefficient of Determination or sometimes also known as Goodness of fit.\n",
    "\n",
    "![R Squared](./img/r2.png)\n",
    "\n",
    "Now, how will you interpret the R2 score? suppose If the R2 score is zero then the above regression line by mean line is equal means 1 so 1-1 is zero. So, in this case, both lines are overlapping means model performance is worst, It is not capable to take advantage of the output column.\n",
    "\n",
    "Now the second case is when the R2 score is 1, it means when the division term is zero and it will happen when the regression line does not make any mistake, it is perfect. In the real world, it is not possible.\n",
    "\n",
    "So we can conclude that as our regression line moves towards perfection, R2 score move towards one. And the model performance improves.\n",
    "\n",
    "The normal case is when the R2 score is between zero and one like 0.8 which means your model is capable to explain 80 per cent of the variance of data.\n",
    "\n",
    "```\n",
    "from sklearn.metrics import r2_score\n",
    "r2 = r2_score(y_test,y_pred)\n",
    "print(r2)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**There's also the RMSPE -- Root Mean Square Percentage Error.**\n",
    "**MAPE -- Mean Absolute Percentage Error**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
