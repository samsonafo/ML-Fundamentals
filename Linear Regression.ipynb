{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7258454b-4c10-4a4b-8c7c-286f40965593",
   "metadata": {},
   "source": [
    "## Simple Linear Regression\n",
    "\n",
    "simple linear regression is a machine learning model with a single explanatory variable.\n",
    "\n",
    "That is, it concerns two-dimensional sample points with one independent variable and one dependent variable (conventionally, the x and y coordinates in a Cartesian coordinate system) and finds a linear function (a non-vertical straight line) that, as accurately as possible, predicts the dependent variable values as a function of the independent variable. \n",
    "\n",
    "The adjective simple refers to the fact that the outcome variable is related to a single predictor. (Wikipedia)\n",
    "\n",
    "![Simple Linear Regression](./img/lin_reg_3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87597a3-c4c8-45a1-8ee5-5df2b53fd59a",
   "metadata": {},
   "source": [
    "The equation of the above line is :\n",
    "\n",
    "```\n",
    "Y= mx + b\n",
    "```\n",
    "\n",
    "Where b is the intercept and m is the slope of the line. So basically, the linear regression algorithm gives us the most optimal value for the intercept and the slope (in two dimensions). \n",
    "\n",
    "The y and x variables remain the same, since they are the data features and cannot be changed. The values that we can control are the intercept(b) and slope(m). \n",
    "\n",
    "There can be multiple straight lines depending upon the values of intercept and slope. Basically what the linear regression algorithm does is it fits multiple lines on the data points and returns the line that results in the least error.\n",
    "\n",
    "![Fitting Linear Regression](./img/fit_lin_reg.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf481bdf-479a-42e9-bdb6-f723c5c41fb4",
   "metadata": {},
   "source": [
    "### Understanding the Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ec7e7b-c715-4a7a-bdfc-702dae50701e",
   "metadata": {},
   "source": [
    "**Linear regression** is a linear approach to modelling the relationship between a scalar response and one or more explanatory variables (also known as dependent and independent variables).\n",
    "\n",
    "The case of one independent variable is called simple linear regression; for more than one, the process is called **multiple linear regression.**\n",
    "\n",
    "Formula and Calculation of Multiple Linear Regression\n",
    "\\begin{aligned}&y_i = \\beta_0 + \\beta _1 x_{i1} + \\beta _2 x_{i2} + ... + \\beta _p x_{ip} + \\epsilon\\\\&\\textbf{where, for } i = n \\textbf{ observations:}\\\\&y_i=\\text{dependent variable}\\\\&x_i=\\text{explanatory variables}\\\\&\\beta_0=\\text{y-intercept (constant term)}\\\\&\\beta_p=\\text{slope coefficients for each explanatory variable}\\\\&\\epsilon=\\text{the model's error term (also known as the residuals)}\\end{aligned}."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02df44e-b8f7-428b-87da-dc7f3f49d35d",
   "metadata": {},
   "source": [
    "#### Assumptions of multiple linear regression:\n",
    "    \n",
    "    \n",
    "Multiple linear regression makes all of the same assumptions as simple linear regression:\n",
    "\n",
    "- Homogeneity of variance (homoscedasticity): the size of the error in our prediction doesnâ€™t change significantly across the values of the independent variable. This ensures that predictions are reliable and consistent.\n",
    "\n",
    "- Independence of observations: the observations in the dataset were collected using statistically valid methods, and there are no hidden relationships among variables.\n",
    "\n",
    "In multiple linear regression, it is possible that some of the independent variables are actually correlated with one another, so it is important to check these before developing the regression model. If two independent variables are too highly correlated (r2 > ~0.6), then only one of them should be used in the regression model.\n",
    "\n",
    "- Normality: The data follows a normal distribution.\n",
    "\n",
    "- Linearity: the line of best fit through the data points is a straight line, rather than a curve or some sort of grouping factor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005f40ac-e956-47b3-9a98-881e2abfc599",
   "metadata": {},
   "source": [
    "#### What is Logistic Regression?\n",
    "\n",
    "\n",
    "Logistic regression is a statistical method for predicting binary classes. The outcome or target variable is dichotomous in nature. Dichotomous means there are only two possible classes. For example, it can be used for cancer detection problems. It computes the probability of an event occurrence.\n",
    "\n",
    "It is a special case of linear regression where the target variable is categorical in nature. It uses a log of odds as the dependent variable. Logistic Regression predicts the probability of occurrence of a binary event utilizing a logit function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d55822-c235-4630-8164-c739744345f0",
   "metadata": {},
   "source": [
    "Linear Regression Equation:\n",
    "\n",
    "![Simple Linear Regression](./img/linear_formula.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041068ac-47ca-425e-b3d8-f816ec5c5797",
   "metadata": {},
   "source": [
    "Where, y is a dependent variable and x1, x2 ... and Xn are explanatory variables.\n",
    "\n",
    "Sigmoid Function:\n",
    "\n",
    "![Simple Linear Regression](./img/sigmoid_function.png)\n",
    "\n",
    "Apply Sigmoid function on linear regression:\n",
    "\n",
    "![Simple Linear Regression](./img/apply_sigmoid.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b3adad-45b1-4190-9efb-251f85d3b429",
   "metadata": {},
   "source": [
    "#### Properties of Logistic Regression:\n",
    "\n",
    "The dependent variable in logistic regression follows Bernoulli Distribution.\n",
    "Estimation is done through maximum likelihood.\n",
    "No R Square, Model fitness is calculated through Concordance, KS-Statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43415c10-a67e-4192-9ca5-b15bb3472581",
   "metadata": {},
   "source": [
    "Linear regression gives you a continuous output, but logistic regression provides a constant output. An example of the continuous output is house price and stock price. Example's of the discrete output is predicting whether a patient has cancer or not, predicting whether the customer will churn. Linear regression is estimated using Ordinary Least Squares (OLS) while logistic regression is estimated using Maximum Likelihood Estimation (MLE) approach.\n",
    "\n",
    "![Simple Linear Regression](./img/Regression_charts.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67842d4e-cddb-4669-b610-98b41b875629",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
