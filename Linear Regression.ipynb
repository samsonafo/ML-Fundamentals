{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7258454b-4c10-4a4b-8c7c-286f40965593",
   "metadata": {},
   "source": [
    "## Simple Linear Regression\n",
    "\n",
    "simple linear regression is a linear regression model with a single explanatory variable.\n",
    "\n",
    "That is, it concerns two-dimensional sample points with one independent variable and one dependent variable (conventionally, the x and y coordinates in a Cartesian coordinate system) and finds a linear function (a non-vertical straight line) that, as accurately as possible, predicts the dependent variable values as a function of the independent variable. \n",
    "\n",
    "The adjective simple refers to the fact that the outcome variable is related to a single predictor. (Wikipedia)\n",
    "\n",
    "![Simple Linear Regression](./img/lin_reg_3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87597a3-c4c8-45a1-8ee5-5df2b53fd59a",
   "metadata": {},
   "source": [
    "The equation of the above line is :\n",
    "\n",
    "```\n",
    "Y= mx + b\n",
    "```\n",
    "\n",
    "Where b is the intercept and m is the slope of the line. So basically, the linear regression algorithm gives us the most optimal value for the intercept and the slope (in two dimensions). \n",
    "\n",
    "The y and x variables remain the same, since they are the data features and cannot be changed. The values that we can control are the intercept(b) and slope(m). \n",
    "\n",
    "There can be multiple straight lines depending upon the values of intercept and slope. Basically what the linear regression algorithm does is it fits multiple lines on the data points and returns the line that results in the least error.\n",
    "\n",
    "![Fitting Linear Regression](./img/fit_lin_reg.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf481bdf-479a-42e9-bdb6-f723c5c41fb4",
   "metadata": {},
   "source": [
    "### Understanding the Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ec7e7b-c715-4a7a-bdfc-702dae50701e",
   "metadata": {},
   "source": [
    "**Linear regression** is a linear approach to modelling the relationship between a scalar response and one or more explanatory variables (also known as dependent and independent variables).\n",
    "\n",
    "The case of one independent variable is called simple linear regression; for more than one, the process is called **multiple linear regression.**\n",
    "\n",
    "Formula and Calculation of Multiple Linear Regression\n",
    "\\begin{aligned}&y_i = \\beta_0 + \\beta _1 x_{i1} + \\beta _2 x_{i2} + ... + \\beta _p x_{ip} + \\epsilon\\\\&\\textbf{where, for } i = n \\textbf{ observations:}\\\\&y_i=\\text{dependent variable}\\\\&x_i=\\text{explanatory variables}\\\\&\\beta_0=\\text{y-intercept (constant term)}\\\\&\\beta_p=\\text{slope coefficients for each explanatory variable}\\\\&\\epsilon=\\text{the model's error term (also known as the residuals)}\\end{aligned}."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02df44e-b8f7-428b-87da-dc7f3f49d35d",
   "metadata": {},
   "source": [
    "#### Assumptions of multiple linear regression:\n",
    "    \n",
    "    \n",
    "Multiple linear regression makes all of the same assumptions as simple linear regression:\n",
    "\n",
    "- Homogeneity of variance (homoscedasticity): the size of the error in our prediction doesnâ€™t change significantly across the values of the independent variable.\n",
    "\n",
    "- Independence of observations: the observations in the dataset were collected using statistically valid methods, and there are no hidden relationships among variables.\n",
    "\n",
    "In multiple linear regression, it is possible that some of the independent variables are actually correlated with one another, so it is important to check these before developing the regression model. If two independent variables are too highly correlated (r2 > ~0.6), then only one of them should be used in the regression model.\n",
    "\n",
    "- Normality: The data follows a normal distribution.\n",
    "\n",
    "- Linearity: the line of best fit through the data points is a straight line, rather than a curve or some sort of grouping factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8caa48-80dc-4a44-839d-48ea75270969",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
