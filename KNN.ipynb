{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8296407-a39a-484e-8e34-85a4c4226ef9",
   "metadata": {},
   "source": [
    "#### K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bff29ae-e443-44ac-93a8-f8f293598ed6",
   "metadata": {},
   "source": [
    "'''The KNN algorithm assumes that similar things exist in close proximity. In other words, similar things are near to each other.'''\n",
    "\n",
    "![k-Nearest-Neigbhour](./img/knn.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11390ee-03fd-4f61-aa3f-ccd90f197c6e",
   "metadata": {},
   "source": [
    "Notice in the image above that most of the time, similar data points are close to each other. \n",
    "\n",
    "The KNN algorithm hinges on this assumption being true enough for the algorithm to be useful. \n",
    "\n",
    "KNN captures the idea of similarity (sometimes called distance, proximity, or closeness) with some mathematics we might have learned in our childhood— calculating the distance between points on a graph."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975e1c06-eb87-42e8-8dc1-78b9807be202",
   "metadata": {},
   "source": [
    "#### When do we use KNN algorithm?\n",
    "\n",
    "KNN can be used for both classification and regression predictive problems. \n",
    "\n",
    "However, it is more widely used in classification problems in the industry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831a8069-117c-4178-a219-a5108f06eb85",
   "metadata": {},
   "source": [
    "##### How does the KNN algorithm work?\n",
    "\n",
    "Let’s take a simple case to understand this algorithm. Following is a spread of red circles (RC) and green squares (GS) :\n",
    "\n",
    "![k-Nearest-Neigbhour](./img/knn-scenario1.png)\n",
    "\n",
    "You intend to find out the class of the blue star (BS). BS can either be RC or GS and nothing else. \n",
    "\n",
    "The “K” is KNN algorithm is the nearest neighbor we wish to take the vote from. Let’s say K = 3. Hence, we will now make a circle with BS as the center just as big as to enclose only three datapoints on the plane. Refer to the following diagram for more details:\n",
    "\n",
    "![k-Nearest-Neigbhour](./img/knn-scenario2.png)\n",
    "\n",
    "The three closest points to BS is all RC. Hence, with a good confidence level, we can say that the BS should belong to the class RC. Here, the choice became very obvious as all three votes from the closest neighbor went to RC. The choice of the parameter K is very crucial in this algorithm. Next, we will understand what are the factors to be considered to conclude the best K."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1972f8b7-84d4-4697-9e9b-05d63d8aacb6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
